{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Agent - Planner and Self-Critique Agents\n",
    "### Web Research with Iterative Self-Improvement\n",
    "\n",
    "Learning Objectives:\n",
    "- Build a research agent with web search\n",
    "- Implement critique agent for quality control\n",
    "- Use reflection loop with max iterations\n",
    "\n",
    "#### Real-World Use Cases:\n",
    "1. **Content Research**: Gather and refine information\n",
    "2. **Report Generation**: Iteratively improve quality\n",
    "3. **Fact Checking**: Verify and enhance accuracy\n",
    "4. **Competitive Analysis**: Research and critique findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"http://localhost:11434\"\n",
    "MODEL_NAME = \"qwen3\"\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=MODEL_NAME, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DuckDuckGo search integration\n",
    "from ddgs import DDGS\n",
    "\n",
    "@tool\n",
    "def web_search(query: str, num_results: int = 5) -> str:\n",
    "    \"\"\"Search the web using DuckDuckGo.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        num_results: Number of results to return (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted search results with titles, descriptions, and URLs\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = list(DDGS().text(query = query,\n",
    "                                   max_results=num_results,\n",
    "                                   region=\"us-en\"))\n",
    "        \n",
    "        if not results:\n",
    "            return f\"No results found for '{query}'\"\n",
    "        \n",
    "        formatted_results = [f\"Search Results for '{query}':\\n\"]\n",
    "        for i, result in enumerate(results, 1):\n",
    "            title = result.get('title', 'No title')\n",
    "            body = result.get('body', 'No description available')\n",
    "            href = result.get('href', '')\n",
    "            formatted_results.append(f\"{i}. **{title}**\\n   {body}\\n   {href}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted_results)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Search error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "web_search.invoke({'query': 'LangGraph tutorials', 'num_results': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, operator.add]\n",
    "    research: str  # stores research output\n",
    "    critique: str  # stores critique feedback\n",
    "    iterations: int  # track iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Researcher Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_node(state: AgentState):\n",
    "\n",
    "    llm_with_tools = llm.bind_tools([web_search])\n",
    "\n",
    "    critique = state.get('critique', '')\n",
    "    iteration = state.get('iterations', 0)\n",
    "\n",
    "    critique_context = \"\"\n",
    "    if critique:\n",
    "        critique_context = f\"\"\"\n",
    "                Previous Critique: {critique}\n",
    "                Address the missing points with new search queries.\n",
    "                \"\"\"\n",
    "\n",
    "    system_prompt = SystemMessage(f\"\"\"\n",
    "        You are a research agent with web search capabilities.\n",
    "        {critique_context}\n",
    "        INSTRUCTIONS:\n",
    "        1. **MUST use web_search tool** first to gather information\n",
    "        2. Provide comprehensive research based on search results\n",
    "\n",
    "        Always call **web_search** before responding.\n",
    "    \"\"\")\n",
    "\n",
    "    messages = [system_prompt] + state['messages']\n",
    "\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "        for tc in response.tool_calls:\n",
    "            print(f\"[RESEARCHER] calling Tool {tc.get('name', '?')} with args {tc.get('args', '?')}\")\n",
    "    else:\n",
    "        print(f\"[RESEARCHER] Iteration {iteration + 1} - Research complete\")\n",
    "\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critique Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critique_node(state: AgentState):\n",
    "    \n",
    "    messages = state['messages']\n",
    "    iteration = state.get('iterations', 0)\n",
    "    \n",
    "    # extract research from messages\n",
    "    research_content = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if hasattr(msg, 'content') and msg.content:\n",
    "            research_content = msg.content\n",
    "            break\n",
    "    \n",
    "    system_prompt = SystemMessage(\"\"\"\n",
    "        You are a critique agent. Evaluate if research is good enough.\n",
    "        \n",
    "        Check:\n",
    "        1. Does it answer the main question?\n",
    "        2. Is there reasonable detail?\n",
    "        \n",
    "        Response Format:\n",
    "        DECISION: APPROVE or REVISE\n",
    "        \n",
    "        Be lenient. APPROVE if research is decent enough.\n",
    "        Only REVISE if critical information is completely missing.\n",
    "    \"\"\")\n",
    "    \n",
    "    critique_prompt = HumanMessage(f\"\"\"\n",
    "        Evaluate this research:\n",
    "        \n",
    "        {research_content}\n",
    "    \"\"\")\n",
    "    \n",
    "    response = llm.invoke([system_prompt, critique_prompt])\n",
    "    \n",
    "    print(f\"[CRITIQUE] Iteration {iteration + 1}\")\n",
    "    \n",
    "    return {\n",
    "        'critique': response.content,\n",
    "        'research': research_content,\n",
    "        'iterations': iteration + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing from researcher\n",
    "def should_continue(state: AgentState):\n",
    "    last = state['messages'][-1]\n",
    "    \n",
    "    if hasattr(last, 'tool_calls') and last.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"critique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing from critique\n",
    "MAX_ITERATIONS = 10\n",
    "\n",
    "def check_approval(state: AgentState):\n",
    "    \n",
    "    critique = state.get('critique', '')\n",
    "    iterations = state.get('iterations', 0)\n",
    "    \n",
    "    # max iterations reached\n",
    "    if iterations >= MAX_ITERATIONS:\n",
    "        print(f\"[SYSTEM] Max iterations ({MAX_ITERATIONS}) reached. Stopping.\")\n",
    "        return END\n",
    "    \n",
    "    # check if approved\n",
    "    if 'APPROVE' in critique.upper():\n",
    "        print(f\"[SYSTEM] Research approved after {iterations} iteration(s)\")\n",
    "        return END\n",
    "    else:\n",
    "        print(f\"[SYSTEM] Revision needed. Continuing iteration {iterations + 1}\")\n",
    "        return \"researcher\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Graph\n",
    "# =============================================================================\n",
    "def create_agent():\n",
    "\n",
    "    builder = StateGraph(AgentState)\n",
    "\n",
    "    builder.add_node(\"researcher\", researcher_node)\n",
    "    builder.add_node(\"tools\", ToolNode([web_search]))\n",
    "    builder.add_node(\"critique\", critique_node)\n",
    "\n",
    "    builder.add_edge(START, \"researcher\")\n",
    "    builder.add_conditional_edges(\"researcher\", should_continue, [\"tools\", \"critique\"])\n",
    "    builder.add_edge(\"tools\", \"researcher\")\n",
    "    builder.add_conditional_edges(\"critique\", check_approval, [\"researcher\", END])\n",
    "\n",
    "    graph = builder.compile()\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent()\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the latest developments in LangGraph for building AI agents?\"\n",
    "\n",
    "result = agent.invoke({\n",
    "    'messages': [HumanMessage(query)],\n",
    "    'research': '',\n",
    "    'critique': '',\n",
    "    'iterations': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final research output\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESEARCH OUTPUT\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(result['research'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Do research on Nvidia stock performance and recent news.\"\n",
    "\n",
    "result = agent.invoke({\n",
    "    'messages': [HumanMessage(query)],\n",
    "    'research': '',\n",
    "    'critique': '',\n",
    "    'iterations': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['research'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['critique'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
